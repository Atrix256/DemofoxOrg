<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Analytical Surfaces Evaluated By the GPU Texture Sampler</title>
<style type="text/css">
body { color: #00FF00; background-color:black;}
canvas#RenderWindow {border:2px solid #00FF00;width:600px; height:600px;}
</style>
<script>
/*=========================================================================================
Created by Alan Wolfe December 2016
http://demofox.org
http://blog.demofox.org
https://twitter.com/Atrix256
=========================================================================================*/

//=========================================================================================
var vertexShaderSource = `#version 300 es
 
// inputs
in vec4 a_position;

// outputs
out vec2 v_uv;

// logic 
void main() {
    v_uv = a_position.xy * 0.5 + 0.5;
    gl_Position = vec4(a_position.xy, 0.0, 1.0);
}
`;
 
//=========================================================================================
var fragmentShaderSourceTop = `#version 300 es

#define NUM_RAY_STEPS 20

precision mediump float;

// inputs
in vec2 v_uv;

// uniforms
uniform float u_time;
uniform vec3 u_mouse;  // z,y:  percent of screen. z: mouse button down or not

// outputs
out vec4 outColor;

bool RayIntersectAABox (vec3 boxMin, vec3 boxMax, in vec3 rayPos, in vec3 rayDir, out vec2 time)
{
    vec3 roo = rayPos - (boxMin+boxMax)*0.5;
    vec3 rad = (boxMax - boxMin)*0.5;

    vec3 m = 1.0/rayDir;
    vec3 n = m*roo;
    vec3 k = abs(m)*rad;
    
    vec3 t1 = -n - k;
    vec3 t2 = -n + k;

    time = vec2( max( max( t1.x, t1.y ), t1.z ),
                 min( min( t2.x, t2.y ), t2.z ) );
    
    return time.y>time.x && time.y>0.0;
}
`;

var fragmentShaderSource11 =`

// Bilinear Code Begin
uniform sampler2D u_texture11;

float SurfaceHeight (vec2 uv)
{
    return texture(u_texture11, (uv + 0.5) / 2.0).r;
}
// Bilinear Code End
`;
 
 var fragmentShaderSourceBottom =`
// logic
void main() {

    //-------------------------
    //----- Camera Setup ------
    //-------------------------

    vec3 cameraAt   = vec3(0.5,0.5,0.5);

    float angleX = u_mouse.z > 0.0 ? 6.28 * u_mouse.x : 3.14 ;
    float angleY = u_mouse.z > 0.0 ? (u_mouse.y * 6.28) - 0.4 : 0.5;
    vec3 cameraPos  = (vec3(sin(angleX)*cos(angleY), sin(angleY), cos(angleX)*cos(angleY))) * 3.0;
    cameraPos += vec3(0.5,0.5,0.5);

    vec3 cameraFwd  = normalize(cameraAt - cameraPos);
    vec3 cameraLeft  = normalize(cross(normalize(cameraAt - cameraPos), vec3(0.0,sign(cos(angleY)),0.0)));
    vec3 cameraUp   = normalize(cross(cameraLeft, cameraFwd));

    float cameraViewWidth   = 6.0;
    float cameraViewHeight  = cameraViewWidth;
    float cameraDistance    = 6.0;  // intuitively backwards!

    //-------------------------
    //------ Ray Setup --------
    //-------------------------

    vec2 percent = v_uv - vec2(0.5,0.5);
    
    vec3 rayTarget = (cameraFwd * vec3(cameraDistance,cameraDistance,cameraDistance))
                   - (cameraLeft * percent.x * cameraViewWidth)
                   + (cameraUp * percent.y * cameraViewHeight);
    vec3 rayDir = normalize(rayTarget);

    //-------------------------
    //------ Ray Trace --------
    //-------------------------
    
    // if the ray misses the bounding box, bail out
    vec2 rayMinMax;
    if (!RayIntersectAABox(vec3(0.0, 0.0, 0.0), vec3(1.0,1.0,1.0), cameraPos, rayDir, rayMinMax))
    {
        outColor = vec4(0.0, 0.0, 0.0, 1.0);
        return;
    }

    // else set the pixel to dark green to show the box boundaries by default
    outColor = vec4(0.0, 0.2, 0.0, 1.0);

    //-------------------------
    //------ Ray March --------
    //-------------------------

    vec3 rayPos = clamp(cameraPos + rayDir * rayMinMax.x, 0.0, 1.0);
    vec3 rayStop = clamp(cameraPos + rayDir * rayMinMax.y, 0.0, 1.0);
    vec3 rayDelta = (rayStop - rayPos) / float(NUM_RAY_STEPS-1);

    bool startedAbove = rayPos.y > SurfaceHeight(rayPos.xz);
    bool hit = false;
    for (int i = 0; i < NUM_RAY_STEPS; ++i)
    {
        bool isAbove = rayPos.y > SurfaceHeight(rayPos.xz);
        hit = (startedAbove != isAbove);
        rayPos = clamp(rayPos + rayDelta, 0.0, 1.0);
    }

    if (hit)
    {
        outColor = vec4(1.0, 0.1, 0.1, 1.0);
    }
}

`;

var gl = null;
var canvas = null;
var uniformTime = null;

//=========================================================================================
function createShader (gl, type, source) {
  var shader = gl.createShader(type);
  gl.shaderSource(shader, source);
  gl.compileShader(shader);
  var success = gl.getShaderParameter(shader, gl.COMPILE_STATUS);
  if (success) {
    return shader;
  }
 
  console.log(gl.getShaderInfoLog(shader));
  gl.deleteShader(shader);
}

//=========================================================================================
function createProgram (gl, vertexShader, fragmentShader) {
  var program = gl.createProgram();
  gl.attachShader(program, vertexShader);
  gl.attachShader(program, fragmentShader);
  gl.linkProgram(program);
  var success = gl.getProgramParameter(program, gl.LINK_STATUS);
  if (success) {
    return program;
  }
 
  console.log(gl.getProgramInfoLog(program));
  gl.deleteProgram(program);
}

//=========================================================================================
function createTextureRGBA (byteArrayWithRGBAData, width, height) {
    var texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, new Uint8Array(byteArrayWithRGBAData));
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.bindTexture(gl.TEXTURE_2D, null);
    return texture;
}

//=========================================================================================
function resize (canvas) {
  // Lookup the size the browser is displaying the canvas.
  var displayWidth  = canvas.clientWidth;
  var displayHeight = canvas.clientHeight;
 
  // Check if the canvas is not the same size.
  if (canvas.width  !== displayWidth ||
      canvas.height !== displayHeight) {
 
    // Make the canvas the same size
    canvas.width  = displayWidth;
    canvas.height = displayHeight;
  }
}

//=========================================================================================
function SetVertexAttributeData (gl, program, name, type, count, values)
{
    var attributeLocation = gl.getAttribLocation(program, name);
    if (attributeLocation == -1)
        return;

    var buffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(values), gl.STATIC_DRAW);        

    gl.enableVertexAttribArray(attributeLocation);
    var size = count; 
    var type = type;   
    var normalize = false; 
    var stride = 0;        
    var offset = 0;        
    gl.vertexAttribPointer(attributeLocation, size, type, normalize, stride, offset);      
}

//=========================================================================================
function DrawScene ()
{
    // update time
    gl.uniform1f(uniformTime, (Date.now()%1000)/1000);

    // make sure gl is rendering to the the right size and has the right viewport info
    resize(gl.canvas);
    gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);

    // draw our single full screen triangle
    var primitiveType = gl.TRIANGLES;
    var offset = 0;
    var count = 3;
    gl.drawArrays(primitiveType, offset, count);    

    // request another frame to be drawn
    requestAnimationFrame(DrawScene);
}

//=========================================================================================
function SetupGL ()
{
    // setup webgl2
	canvas = document.getElementById("RenderWindow");
	gl = canvas.getContext("webgl2");
	if (!gl)
	{
		alert("This page requires WebGL2, which doesn't seem to be enabled ):");
		return;
	}

    // compile shaders
	var vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
	var fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSourceTop + fragmentShaderSource11 + fragmentShaderSourceBottom);
	var program = createProgram(gl, vertexShader, fragmentShader);

    // vertex data - a single triangle that covers the screen
    var vao = gl.createVertexArray();
    gl.bindVertexArray(vao);
    SetVertexAttributeData(gl, program, "a_position", gl.FLOAT, 2,
        [
            -1,  3,
             3, -1,
            -1, -1,
        ]
    );   

    // get uniforms
    uniformTime = gl.getUniformLocation(program, "u_time"); 

    // one time setup
    gl.clearColor(0, 0, 0, 0);
    gl.useProgram(program); 

    var textureData = [
         20, 0, 0, 0,   40, 0, 0, 0,
         60, 0, 0, 0,   50, 0, 0, 0
    ];

    texture11 = createTextureRGBA(
        textureData,
        2, 2
    );

    var uniformTexture11 = gl.getUniformLocation(program, "u_texture11"); 
    gl.activeTexture(gl.TEXTURE0);
    gl.bindTexture(gl.TEXTURE_2D, texture11);
    gl.uniform1i(uniformTexture11, 0);


    // start the render loop
    requestAnimationFrame(DrawScene);
}


</script>
</head>
<body onLoad="SetupGL()">
<h1>Analytical Surfaces Evaluated By the GPU Texture Sampler</h1>

This page uses WebGL2, which will be enabled by default in chrome 56 in January 2017.<br>
To enable WebGL2 before then on chrome or other browsers, see this link:
<a href="http://webgl2fundamentals.org/webgl/lessons/webgl-getting-webgl2.html" target="_blank">How to use WebGL2</a><br>
<br>
<canvas id="RenderWindow"></canvas>


</body></html>

<br>
<hr>
<pre>
TODO:
* make texture use a single color channel, after you get it working for bilinear case! R8 format doesnt seem to work, first try ):
* get raytracing / raymarching working with a dumb height field to start (sine based?)
* copy code from https://www.shadertoy.com/view/XtfSRj
* hook up u_mouse so the camera can rotate? Or have JS tell shader the camera position and have it handle it?

* shade the points!

* get rid of u_time, don't need it!
* v_uv is converted from -1,1 to 0,1 in VS, then converted back in PS. Maybe rename it and make it stay -1,1!

* write out to console to do error handling, wherever something can go wrong

* explain how it's rendered. raytrace then ray march.  Mention that the raytrace could be replaced by drawing the cube (with back face culling) to do rasterization instead of full screen pass!
* also, for each surface type chosen, show texture layout and shader code source.

* Workings
 * 3d volume texture RGBA for storage
 * let you specify bernstein coefficients
 * show it as raymarched surface.  show isolines.  raytrace cube, then raymarch interior.
 * drop down for surface degree: (1,1),  (2,1), (2,2), (3,3)
* show fps
* should we show texture layout and shader code? maybe just texture layout and instructions for sampling surface?
* link to post on how to convert polys to bernstein
* volume demo after this
* link to blog post
* have blog post link to this
* link to demos from main bezier page as well
* link to http://webgl2fundamentals.org/
* checkbox for control points and containing box.

* clean up this code / add comments etc?
? get demofox.org into this repository?
? is there a way to back up wordpress into git as well?
</pre>